{
  "tasks": [
    {
      "id": "T-001",
      "title": "E00 Spike: choose region/Eventarc routing for Firestore trigger",
      "description": "Epic 0 (Cloud environment + deploy pipeline): decide and document region alignment (Firestore DB, Eventarc trigger, Cloud Functions gen2) and update @docs/questions/open_questions.md / @docs/spec/deploy_and_envs.md if needed.",
      "status": "DONE",
      "priority": "low",
      "owner": "DOCS",
      "tags": [
        "epic0",
        "spike",
        "gcp",
        "eventarc"
      ],
      "depends_on": [],
      "commit": {
        "hash": "d8ad63a33a83253942c89b3808f6661e9ad5c4e1",
        "message": "üó∫Ô∏è T-001 align region routing"
      }
    },
    {
      "id": "T-002",
      "title": "E00 Spike: define least-privilege IAM for runtime/trigger SAs",
      "description": "Epic 0 (Cloud environment + deploy pipeline): enumerate minimal IAM roles for runtime SA and Eventarc trigger SA (Firestore, GCS, Secret Manager, Eventarc) and document in @docs/spec/deploy_and_envs.md + runbook.",
      "status": "DONE",
      "priority": "low",
      "owner": "DOCS",
      "tags": [
        "epic0",
        "spike",
        "iam",
        "gcp"
      ],
      "depends_on": [],
      "commit": {
        "hash": "71aa4a980cfbd744d3f97ab17cdd7590a0a89a2a",
        "message": "üîê T-002 IAM least-privilege"
      }
    },
    {
      "id": "T-003",
      "title": "E00 Define dev GCP bootstrap checklist and required resources",
      "description": "Epic 0 (Cloud environment + deploy pipeline): produce a concrete dev-environment bootstrap checklist (project/region/Firestore DB/buckets/SA/Secret Manager) aligned to decisions from SPK-017/018; update @docs/spec/deploy_and_envs.md and add a runbook entry.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic0",
        "docs",
        "gcp"
      ],
      "depends_on": [
        "T-001",
        "T-002"
      ],
      "commit": {
        "hash": "c183c0d7e2291c8f14c1f10fae904272b19c49c8",
        "message": "üß∞ T-003 dev bootstrap checklist"
      }
    },
    {
      "id": "T-004",
      "title": "E00 Add deploy pipeline command/script for Cloud Functions gen2",
      "description": "Epic 0 (Cloud environment + deploy pipeline): implement a repeatable deploy/update command (e.g. Makefile target or script) using the gcp-functions-gen2-python-deploy playbook; keep placeholders for secrets/IDs; include env vars file handling.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic0",
        "deploy",
        "gcp",
        "pipeline"
      ],
      "depends_on": [
        "T-003"
      ],
      "commit": {
        "hash": "228ba0c77a421088db7bc107f4a194a1d7a08686",
        "message": "üìù T-004 T-007 deploy lessons learned"
      }
    },
    {
      "id": "T-005",
      "title": "E00 Add smoke-check runbook + Cloud Logging queries",
      "description": "Epic 0 (Cloud environment + deploy pipeline): document smoke scenario and log queries (jsonPayload.event chain, runId/stepId filters) plus GCS artifact checks; align with deploy pipeline.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic0",
        "docs",
        "logging",
        "smoke"
      ],
      "depends_on": [
        "T-003",
        "T-004"
      ],
      "commit": {
        "hash": "341ddaa580095f0ce885655fd3fd24b1d84ce277",
        "message": "üß™ T-005 smoke runbook"
      }
    },
    {
      "id": "T-006",
      "title": "E00 Verify dev deploy pipeline + smoke scenario (DoD)",
      "description": "Epic 0 (Cloud environment + deploy pipeline): run the deploy/update flow in dev and execute the smoke-check runbook; use gcp-functions-gen2-python-deploy playbook verification steps; record evidence in @.codex-swarm/workspace/T-006/README.md.",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic0",
        "verify",
        "cloud"
      ],
      "depends_on": [
        "T-004",
        "T-005"
      ],
      "commit": {
        "hash": "85d244ce58853bb39661e1cc41ff8d3142739b05",
        "message": "üß™ T-006 record smoke verification"
      }
    },
    {
      "id": "T-007",
      "title": "E00 Add minimal Cloud Functions stub for deploy testing",
      "description": "Epic 0 (Cloud environment + deploy pipeline): add a minimal main.py + requirements.txt (+ .gcloudignore) so the deploy script can be exercised safely before real implementation.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic0",
        "deploy",
        "stub"
      ],
      "depends_on": [
        "T-004"
      ],
      "commit": {
        "hash": "901d498be7a6ee0883a99ba17b5b544fe5d83d80",
        "message": "üßπ T-007 ignore gcloud config"
      }
    },
    {
      "id": "T-008",
      "title": "E01 Spike: confirm Gemini endpoint + SDK constraints",
      "description": "Epic 1 spike (SPK-007): confirm the production endpoint decision (AI Studio vs Vertex AI) and SDK support for structured output + image parts; update @docs/spec/system_integration.md, @docs/spec/deploy_and_envs.md, and @docs/questions/open_questions.md if any decision changes are needed.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic1",
        "spike",
        "gemini"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "DOCS",
          "body": "Start: review official Gemini API + Google GenAI SDK docs to confirm endpoint choice and SDK constraints for structured output + image inputs; update docs per Epic 1 spike."
        },
        {
          "author": "DOCS",
          "body": "Verified: docs-only update; no runtime changes; no tests run."
        }
      ],
      "commit": {
        "hash": "b01f399f8ac79236a7962d1ae4a007b3fd6e3df2",
        "message": "üìù T-008 confirm Gemini endpoint + SDK constraints"
      }
    },
    {
      "id": "T-009",
      "title": "E01 Spike: define model allowlist policy",
      "description": "Epic 1 spike (SPK-020): define and document the allowed-models policy (format/location of allowlist, enforcement strategy, and error mapping for disallowed models) and update @docs/spec/deploy_and_envs.md and @docs/spec/system_integration.md accordingly.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic1",
        "spike",
        "config"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "DOCS",
          "body": "Start: define allowed-models policy and doc updates for Epic 1 (allowlist format, enforcement, error mapping)."
        },
        {
          "author": "DOCS",
          "body": "Verified: docs-only update; no runtime changes; no tests run."
        }
      ],
      "commit": {
        "hash": "a98c69b3f6b5cef69f1b3bd00660cc23db265031",
        "message": "üìù T-009 document model allowlist policy"
      }
    },
    {
      "id": "T-010",
      "title": "E01 Implement WorkerConfig + Gemini auth config",
      "description": "Implement Epic 1 classes: WorkerConfig, GeminiApiKey, GeminiAuthConfig. Validate env config (collections, bucket, timeouts, log level) and support single-key auth via GEMINI_API_KEY only; do not leak secrets; wire config into the runtime entrypoint.",
      "status": "DONE",
      "priority": "high",
      "owner": "CODER",
      "tags": [
        "epic1",
        "config",
        "runtime"
      ],
      "depends_on": [
        "T-008",
        "T-009"
      ],
      "comments": [
        {
          "author": "CODER",
          "body": "Start: implement WorkerConfig/GeminiAuthConfig single-key mode only; validate env and wire into entrypoint."
        },
        {
          "author": "CODER",
          "body": "Verified: manual config sanity check with ARTIFACTS_BUCKET and GEMINI_API_KEY; output: config ok."
        }
      ],
      "commit": {
        "hash": "facf2e6dd595ba4d96a1b424d6b674799f120120",
        "message": "‚ú® T-010 add runtime config + Gemini auth"
      }
    },
    {
      "id": "T-011",
      "title": "E01 Add unit tests for runtime config",
      "description": "Add unit tests for WorkerConfig.from_env() and Gemini auth parsing: single-key happy path, missing/empty key errors; assert error messages do not include the API key or its hash.",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic1",
        "tests"
      ],
      "depends_on": [
        "T-010"
      ],
      "comments": [
        {
          "author": "TESTER",
          "body": "Start: add unit tests for WorkerConfig single-key validation and safe error messaging."
        },
        {
          "author": "TESTER",
          "body": "Verified: python3 -m unittest tests.test_config ran OK; 4 tests passed."
        }
      ],
      "commit": {
        "hash": "d39626de9fcd425bdb699c67172f098b6d1d1fd7",
        "message": "üß™ T-011 add WorkerConfig tests"
      }
    },
    {
      "id": "T-012",
      "title": "E01 Dev verify secret injection + logging",
      "description": "Using the dev deploy pipeline from Epic 0, verify Secret Manager ‚Üí env var injection for GEMINI_API_KEY and confirm logs include only llm.auth.mode (no key or keyId); record evidence in @.codex-swarm/workspace/T-012/README.md.",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic1",
        "verify",
        "cloud"
      ],
      "depends_on": [
        "T-010",
        "T-011"
      ],
      "comments": [
        {
          "author": "TESTER",
          "body": "Start: verify Secret Manager ‚Üí GEMINI_API_KEY injection and log fields in dev (cloud)."
        },
        {
          "author": "TESTER",
          "body": "Verified: deploy update succeeded and GEMINI_API_KEY secret injected; log field check pending Epic 2 (structured logging)."
        }
      ],
      "commit": {
        "hash": "d88ffc4f298326d90f3e14cb09842454ace1f586",
        "message": "üßæ T-012 record dev deploy evidence"
      }
    },
    {
      "id": "T-013",
      "title": "E01 Epic 1 DoD verification + stabilization",
      "description": "Final Epic 1 verification: run local test suite for config/auth and confirm dev smoke results meet Epic 1 DoD (validated config, no secret leakage, single-key auth). Update @.codex-swarm/workspace/T-013/README.md with results and any stabilization notes.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic1",
        "verify",
        "stabilization"
      ],
      "depends_on": [
        "T-012"
      ],
      "comments": [
        {
          "author": "INTEGRATOR",
          "body": "Start: run final Epic 1 verification and record results."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: local config tests (python3 -m unittest tests.test_config) OK; dev secret injection confirmed in T-012; log field check pending Epic 2."
        }
      ],
      "commit": {
        "hash": "b459328a9c7ed1add3fd57a506c6015008d2d47a",
        "message": "üßæ T-013 record Epic 1 verification"
      }
    },
    {
      "id": "T-014",
      "title": "E02 Spike: define minimal logging schema + safety gates",
      "description": "Epic 2 spike (SPK-013): confirm minimal structured logging envelope requirements and safe-field gating; update @docs/spec/observability.md if needed.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic2",
        "spike",
        "logging"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "DOCS",
          "body": "Start: confirm minimal logging schema and safety gates; update observability spec if needed."
        },
        {
          "author": "DOCS",
          "body": "Verified: logging safety gates documented; SPK-013 resolved in arch spikes backlog."
        }
      ],
      "commit": {
        "hash": "e11c97eea1235b915bc7ab2924aee59b96becfeb",
        "message": "üìù T-014 define logging safety gates"
      }
    },
    {
      "id": "T-015",
      "title": "E02 Implement structured EventLogger",
      "description": "Implement Epic 2 classes EventLogger + CloudLoggingEventLogger with required envelope fields, safe field filtering, and stable event taxonomy; integrate into entrypoint stub for visibility.",
      "status": "DONE",
      "priority": "high",
      "owner": "CODER",
      "tags": [
        "epic2",
        "logging",
        "runtime"
      ],
      "depends_on": [
        "T-014"
      ],
      "comments": [
        {
          "author": "CODER",
          "body": "Start: implement EventLogger + CloudLoggingEventLogger with safety gates; wire into entrypoint."
        },
        {
          "author": "CODER",
          "body": "Verified: EventLogger wired into stub; emits cloud_event_received with required envelope fields."
        }
      ],
      "commit": {
        "hash": "198abf3f50f17641e94adbb6a950f9695c36a7d1",
        "message": "‚ú® T-015 implement EventLogger"
      }
    },
    {
      "id": "T-016",
      "title": "E02 Add unit tests for logging envelope",
      "description": "Add tests ensuring EventLogger enforces required fields, rejects dangerous payloads, and produces stable JSON for key events (cloud_event_received, cloud_event_parsed, claim_attempt, llm_request_started, gcs_write_finished, step_completed/step_failed).",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic2",
        "tests",
        "logging"
      ],
      "depends_on": [
        "T-015"
      ],
      "comments": [
        {
          "author": "TESTER",
          "body": "Start: add tests for EventLogger envelope and safety gates."
        },
        {
          "author": "TESTER",
          "body": "Verified: python3 -m unittest tests.test_logging OK; logging envelope aligns with spec (stepId required only when applicable)."
        }
      ],
      "commit": {
        "hash": "b8ecfdea4700b1138138458d1b02530a6cc3cf9f",
        "message": "üß™ T-016 add logging tests"
      }
    },
    {
      "id": "T-017",
      "title": "E02 Dev verify logging chain",
      "description": "Deploy updated function in dev and verify Cloud Logging event chain is observable by runId/stepId/eventId with no prompt/raw output leakage; record evidence in @.codex-swarm/workspace/T-017/README.md.",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic2",
        "verify",
        "cloud"
      ],
      "depends_on": [
        "T-015",
        "T-016"
      ],
      "comments": [
        {
          "author": "TESTER",
          "body": "Start: deploy updated logging and verify Cloud Logging event chain in dev."
        },
        {
          "author": "TESTER",
          "body": "Ran Firestore PATCH on flow_runs/20251224-061000_LINKUSDT_demo92 (debug.lastPing). Request log shows POST 200 at 2025-12-29T13:38:22Z; no cloud_event_received app logs found in last 30m. Pending follow-up."
        },
        {
          "author": "TESTER",
          "body": "Root cause likely INFO logs dropped by preconfigured root logger. Added JsonFormatter + configure_logging and switched EventLogger to log dict payloads; main.py now calls configure_logging before/after config load. Pending redeploy + verify."
        },
        {
          "author": "TESTER",
          "body": "Redeployed (revision worker-llm-client-00006-rop). Firestore PATCH at 2025-12-29T14:13:01Z; cloud_event_received log present at 2025-12-29T14:13:02Z (eventId 33199a62-90cd-4549-8cd5-289b3acaf420)."
        }
      ],
      "commit": {
        "hash": "511847073db01809c6b529ec86ffac720b9aafe1",
        "message": "üß™ T-017 fix logging config"
      }
    },
    {
      "id": "T-018",
      "title": "E02 Epic 2 DoD verification + stabilization",
      "description": "Final Epic 2 verification: run local logging tests and confirm dev smoke/log chain meets observability DoD; update @.codex-swarm/workspace/T-018/README.md with results and any stabilization notes.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic2",
        "verify",
        "stabilization"
      ],
      "depends_on": [
        "T-017"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Starting Epic 2 DoD verification + stabilization."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified logging tests: pytest tests/test_logging.py (6 passed). Dev log chain verified: Firestore PATCH at 2025-12-29T14:13:01Z, cloud_event_received log at 2025-12-29T14:13:02Z."
        }
      ],
      "commit": {
        "hash": "a0338d3979d7aaa9f2f67f471a7384000dc220d0",
        "message": "üß™ T-018 update logging test expectations"
      }
    },
    {
      "id": "T-019",
      "title": "E03 Spike: FlowRun validation subset + error codes",
      "description": "Epic 3 spikes (SPK-011, SPK-019): document required-subset validation for flow_runs and explicit error-code mapping (run vs step) aligned to static_model; update @docs/spec/implementation_contract.md, @docs/contracts/flow_run.md, @docs/spec/error_and_retry_model.md as needed.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic3",
        "spike",
        "contracts",
        "errors"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "DOCS",
          "body": "Starting SPK-011/019: required subset validation + error-code mapping."
        }
      ],
      "commit": {
        "hash": "17f8ca8091464b33081c1cba0215ae2021410c52",
        "message": "üìù T-019 document flow_run validation subset"
      }
    },
    {
      "id": "T-020",
      "title": "E03 Implement workflow domain models",
      "description": "Implement FlowRun, FlowStep, LLMReportStep, LLMReportInputs, StepError, ErrorCode in workflow/domain.py per static_model + implementation_contract; enforce minimal validation and stepId safety.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic3",
        "domain"
      ],
      "depends_on": [
        "T-019"
      ],
      "comments": [
        {
          "author": "CODER",
          "body": "Starting Epic 3 domain model implementation."
        }
      ],
      "commit": {
        "hash": "4e6399e88666f7909b1eb9ad085c7c5d86161d05",
        "message": "üß± T-020 add workflow domain models"
      }
    },
    {
      "id": "T-021",
      "title": "E03 Implement ReadyStepSelector policy",
      "description": "Implement ReadyStepSelector in workflow/policies.py: deterministic READY LLM_REPORT selection, run status gate, dependency SUCCEEDED check, and no-op reasons.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic3",
        "domain"
      ],
      "depends_on": [
        "T-020"
      ],
      "comments": [
        {
          "author": "CODER",
          "body": "Starting ReadyStepSelector implementation."
        }
      ],
      "commit": {
        "hash": "8c6abe4ab6e20cafe44091d9393683a482d12458",
        "message": "üß≠ T-021 implement ReadyStepSelector"
      }
    },
    {
      "id": "T-022",
      "title": "E03 Add unit tests for step selection + inputs",
      "description": "Add unit tests for ReadyStepSelector and LLMReportInputs resolution/error mapping using flow_run fixtures; cover no-op/READY/blocked/deterministic selection.",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic3",
        "tests"
      ],
      "depends_on": [
        "T-020",
        "T-021"
      ],
      "comments": [
        {
          "author": "TESTER",
          "body": "Starting unit tests for selector and inputs."
        }
      ],
      "commit": {
        "hash": "1ea362dd13d9784e32a21ce14f52bc7f06812129",
        "message": "üß™ T-022 add workflow domain tests"
      }
    },
    {
      "id": "T-023",
      "title": "E03 Epic 3 DoD verification + stabilization",
      "description": "Run local verification for Epic 3 (domain/selector tests) and document results in @.codex-swarm/workspace/T-023/README.md.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic3",
        "verify"
      ],
      "depends_on": [
        "T-022"
      ],
      "verify": [
        "python3 -m pytest -q"
      ],
      "comments": [
        {
          "author": "INTEGRATOR",
          "body": "Starting Epic 3 DoD verification + stabilization."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: python3 -m pytest -q (22 passed)."
        }
      ],
      "commit": {
        "hash": "1560d812f501febd89c148140fddcd8f1d1ba1ce",
        "message": "üß™ T-023 verify epic3 tests"
      }
    },
    {
      "id": "T-024",
      "title": "E04 Spike: claim/finalize precondition handling",
      "description": "Epic 4 spike (SPK-003/004/005): document Firestore update_time precondition strategy, stepId storage-safety, and no-op vs error behavior for claim/finalize; update specs if needed.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic4",
        "spike",
        "firestore"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "DOCS",
          "body": "Starting SPK-003/005 doc updates for claim/finalize behavior."
        }
      ],
      "commit": {
        "hash": "52666638f9c75ecabf02f34ad0ed25ecfe481ef0",
        "message": "üìù T-024 document claim/finalize policy"
      }
    },
    {
      "id": "T-025",
      "title": "E04 Implement FlowRunRepository port + claim/finalize models",
      "description": "Implement FlowRunRepository interface + ClaimResult/FinalizeResult models and helper update builders; define dotted-path updates and precondition error mapping.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic4",
        "firestore"
      ],
      "depends_on": [
        "T-024"
      ],
      "comments": [
        {
          "author": "CODER",
          "body": "Starting FlowRunRepository port + claim/finalize models."
        }
      ],
      "commit": {
        "hash": "97446f688df52224d1aa481d6dab19a45aab4b87",
        "message": "üß© T-025 add FlowRunRepository port"
      }
    },
    {
      "id": "T-026",
      "title": "E04 Implement FirestoreFlowRunRepository",
      "description": "Add FirestoreFlowRunRepository with get/claim/finalize using update_time preconditions; handle retries for FailedPrecondition/Conflict/Aborted; enforce stepId safety.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic4",
        "firestore"
      ],
      "depends_on": [
        "T-025"
      ],
      "comments": [
        {
          "author": "CODER",
          "body": "Starting FirestoreFlowRunRepository implementation."
        }
      ],
      "commit": {
        "hash": "1d1ed5b97a7450c749081e4244168713079df128",
        "message": "üß© T-026 implement FirestoreFlowRunRepository"
      }
    },
    {
      "id": "T-027",
      "title": "E04 Add unit tests for claim/finalize",
      "description": "Unit tests for FlowRunRepository claim/finalize semantics with fake snapshots/update_time; cover claim conflict, finalize already_final/not_running, and stepId invalid cases.",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic4",
        "firestore",
        "tests"
      ],
      "depends_on": [
        "T-025",
        "T-026"
      ],
      "comments": [
        {
          "author": "TESTER",
          "body": "Starting claim/finalize unit tests."
        }
      ],
      "commit": {
        "hash": "937bb40e8cea45aa479956c7b093668537c61d04",
        "message": "üß™ T-027 add claim/finalize tests"
      }
    },
    {
      "id": "T-028",
      "title": "E04 Epic 4 DoD verification + stabilization",
      "description": "Run local tests for Epic 4 claim/finalize behavior and document results in @.codex-swarm/workspace/T-028/README.md.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic4",
        "verify"
      ],
      "depends_on": [
        "T-027"
      ],
      "verify": [
        "python3 -m pytest -q"
      ],
      "comments": [
        {
          "author": "INTEGRATOR",
          "body": "Starting Epic 4 DoD verification + stabilization."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: python3 -m pytest -q (31 passed). Warning: google.api_core Python 3.10 EOL notice."
        }
      ],
      "commit": {
        "hash": "6e726f3632edacd13f026e0e0577fa9e1529ea9e",
        "message": "üß™ T-028 verify epic4 tests"
      }
    },
    {
      "id": "T-029",
      "title": "E05 Spike: prompt/schema registry invariants",
      "description": "Epic 5 spikes (SPK-006, SPK-016): document schema validation/tooling, schemaSha256 policy, and prompt/schema versioning/immutability; update specs/contracts as needed. Include a checklist of Firestore seed docs for dev/debug (llm_prompts/{promptId} valid + missing cases, llm_schemas/{schemaId} valid + invalid cases, and sample flow_runs/{runId} referencing them) to support the T-033 demo.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic5",
        "spike",
        "schema",
        "prompt"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "DOCS",
          "body": "Starting prompt/schema registry invariant docs + Firestore seed checklist."
        },
        {
          "author": "DOCS",
          "body": "Seeded Firestore (dev) IDs: llm_prompts/llm_report_prompt_v1; llm_schemas/llm_report_output_v1 (valid) + llm_report_output_v2 (invalid); flow_runs/20251230-120000_LINKUSDT_demo8 (valid) / 20251230-120500_LINKUSDT_demo8_missing_prompt / 20251230-121000_LINKUSDT_demo8_invalid_schema."
        }
      ],
      "commit": {
        "hash": "655d549824d0c6f4be5095f13e6174b0628460eb",
        "message": "üìù T-029 record Firestore seed IDs"
      }
    },
    {
      "id": "T-030",
      "title": "E05 Implement PromptRepository + FirestorePromptRepository",
      "description": "Implement PromptRepository port + FirestorePromptRepository for llm_prompts/{promptId}, with error mapping and safe logging rules. Also add minimal handler wiring to fetch prompt for the selected READY LLM_REPORT step and emit prompt_fetch_started/prompt_fetch_finished or PROMPT_NOT_FOUND logs (no LLM call yet) so the Epic 5 prod demo in T-033 is possible.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic5",
        "prompt",
        "firestore"
      ],
      "depends_on": [
        "T-029"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: prepare fixture docs for Firestore seeds + validation checks."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: not run (not requested); changes are prompt repo + handler wiring only."
        }
      ],
      "commit": {
        "hash": "2b42d42fa161563803d0a59f63ceba99a5c730f5",
        "message": "‚ú® T-030 prompt repo + prompt fetch logs"
      }
    },
    {
      "id": "T-031",
      "title": "E05 Implement SchemaRepository + FirestoreSchemaRepository",
      "description": "Implement SchemaRepository port + FirestoreSchemaRepository for llm_schemas/{schemaId}, including minimal schema invariants validation and schemaSha256 policy. Extend the same handler wiring to fetch schema and emit structured_output_schema_invalid / LLM_PROFILE_INVALID logs on invalid schema so the Epic 5 prod demo in T-033 is possible (no LLM call yet).",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic5",
        "schema",
        "firestore"
      ],
      "depends_on": [
        "T-029"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement schema repository + invariants validation and logging."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: not run (not requested); schema repo + handler wiring only."
        }
      ],
      "commit": {
        "hash": "49234a35ab300615e64f99b26150145a151af511",
        "message": "‚ú® T-031 schema repo + schema validation logs"
      }
    },
    {
      "id": "T-032",
      "title": "E05 Add unit tests for prompt/schema repositories",
      "description": "Unit tests for PromptRepository/SchemaRepository (missing docs, invalid schema invariants, transient errors) plus coverage for prompt/schema fetch logging paths used by the demo wiring.",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic5",
        "tests"
      ],
      "depends_on": [
        "T-030",
        "T-031"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: add unit tests for prompt/schema repositories and logging paths."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: unittest discover ran; 45 tests OK (warning about py3.10 EOL)."
        }
      ],
      "commit": {
        "hash": "9714bf7691581cc79b7f50be02dfcbafcced4b74",
        "message": "üß™ T-032 fix handler test"
      }
    },
    {
      "id": "T-033",
      "title": "E05 Epic 5 DoD verification + stabilization",
      "description": "Epic 5 DoD verification (prod demo + local tests). Prereqs: prod deploy of worker; Firestore has seed docs; runtime SA has Firestore/Secret Manager access; logs enabled. Seed data counts: at least 1 prompt doc (llm_prompts/{promptId}), at least 1 schema doc (llm_schemas/{schemaId}), and at least 1 flow_runs/{runId} with a READY LLM_REPORT referencing those IDs. Negative scenarios: yes‚Äîuse one invalid/missing promptId (expect PROMPT_NOT_FOUND) and one invalid schema (missing required summary fields ‚Üí LLM_PROFILE_INVALID). Prep steps: (1) confirm prod function active, (2) insert/verify prompt+schema docs (1 valid + 1 invalid), (3) create/update flow_runs/{runId} with READY step and valid inputs, (4) create/update a second run or step variant for negative cases. Demo steps: (1) update flow_runs/{runId} to trigger Firestore event, (2) watch Cloud Logging for cloud_event_received ‚Üí cloud_event_parsed ‚Üí prompt_fetch_* / structured_output_schema_invalid or prompt_not_found, (3) confirm no prompt/raw output in logs. Expected result: logs show prompt/schema fetch behavior consistent with spec; missing/invalid docs yield PROMPT_NOT_FOUND or LLM_PROFILE_INVALID with sanitized error; no secrets/payloads in logs. Record output in @.codex-swarm/workspace/T-033/README.md.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic5",
        "verify"
      ],
      "depends_on": [
        "T-032"
      ],
      "verify": [
        "python3 -m pytest -q"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: prep Epic5 demo checklist and expected outcomes."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: demo runs executed in cloud; logs captured for positive and negative cases."
        }
      ],
      "commit": {
        "hash": "2767320bbcae9848235c1384db83ce54ab26e134",
        "message": "üõ†Ô∏è T-033 deploy fix + demo report"
      }
    },
    {
      "id": "T-034",
      "title": "E06 Spike: artifact idempotency + path policy",
      "description": "Resolve SPK-002/SPK-012: document GCS create-only semantics (ifGenerationMatch=0 + AlreadyExists reuse) and split-brain recovery behavior; define ArtifactPathPolicy rules (prefix normalization, timeframe/stepId validation) per spec. Update docs (implementation_contract/system_integration/static_model) and mark SPK-002/SPK-012 resolved in arch_spikes.md.",
      "status": "DONE",
      "priority": "high",
      "owner": "DOCS",
      "tags": [
        "epic6",
        "spike",
        "gcs",
        "artifacts"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: spike GCS idempotency + ArtifactPathPolicy rules; update docs + arch_spikes."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: docs updated (artifact semantics + prefix normalization); SPK-002/SPK-012 marked resolved."
        }
      ],
      "commit": {
        "hash": "a1c33461f065c5d2da42e143c5332238636e396a",
        "message": "üìù T-034 doc artifact semantics"
      }
    },
    {
      "id": "T-035",
      "title": "E06 Implement GcsUri + ArtifactPathPolicy + LLMReportFile",
      "description": "Implement artifacts domain: GcsUri value object (parse/validate gs:// URIs) and ArtifactPathPolicy (deterministic <prefix>/<runId>/<timeframe>/<stepId>.json with prefix normalization + invariant checks incl. timeframe vs stepId). Add LLMReportFile DTO matching contracts/llm_report_file.schema.json. Place per static_model: artifacts/domain.py + reporting/domain.py. No I/O yet.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic6",
        "gcs",
        "artifacts"
      ],
      "depends_on": [
        "T-034"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement GcsUri + ArtifactPathPolicy + LLMReportFile DTO."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: not run (not requested); artifacts/reporting domains added."
        }
      ],
      "commit": {
        "hash": "a2dd89b27571411dc7561086928918b95f1167b9",
        "message": "‚ú® T-035 artifacts domain primitives"
      }
    },
    {
      "id": "T-036",
      "title": "E06 Implement ArtifactStore + GcsArtifactStore",
      "description": "Add ArtifactStore port and GcsArtifactStore adapter (artifacts/services.py + infra/gcs.py or similar) with create-only writes (ifGenerationMatch=0). Treat AlreadyExists as success/reuse to support split-brain recovery. Include read/exists helpers, contentType, and write result (created vs reused); map transient GCS errors to retryable codes.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic6",
        "gcs",
        "artifacts"
      ],
      "depends_on": [
        "T-035"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement ArtifactStore + GcsArtifactStore with create-only semantics."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: not run (not requested); artifact store + GCS adapter added."
        }
      ],
      "commit": {
        "hash": "f31ccc4beb7d1d8b5562009884daad95ca4f52ad",
        "message": "‚ú® T-036 artifact store + GCS adapter"
      }
    },
    {
      "id": "T-037",
      "title": "E06 Tests: ArtifactPathPolicy + ArtifactStore",
      "description": "Unit tests for GcsUri + ArtifactPathPolicy (gs:// validation, prefix normalization, deterministic path, timeframe/stepId invariants) and ArtifactStore create-only semantics (AlreadyExists -> reused). Include test for write result flags (created vs reused).",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic6",
        "tests"
      ],
      "depends_on": [
        "T-035",
        "T-036"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: add tests for GcsUri, ArtifactPathPolicy, ArtifactStore semantics."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: unittest discover ran; 53 tests OK (warning about py3.10 EOL)."
        }
      ],
      "commit": {
        "hash": "d29d3c2eaa20e8e15eee65b4dad7d2b31b27dd35",
        "message": "üß™ T-037 record test run"
      }
    },
    {
      "id": "T-038",
      "title": "E06 Epic 6 DoD verification (dev)",
      "description": "Epic 6 cloud DoD verification (dev).\\n\\nPrerequisites:\\n- Latest function revision deployed (post Epic 6 code + ARTIFACTS_DRY_RUN stub) and ACTIVE.\\n- Firestore seed docs exist (prompt + schema + flow_runs with READY LLM_REPORT) from Epic 5 demo.\\n- Runtime SA has Firestore + GCS access; ARTIFACTS_BUCKET configured.\\n- ARTIFACTS_DRY_RUN=true set in env for demo (stub writes test artifact without Gemini).\\n- GCS bucket reachable and empty path for target runId/timeframe/stepId is known.\\n\\nPreparation steps:\\n1) Confirm deployed revision and env vars (LOG_LEVEL=INFO, ARTIFACTS_BUCKET set, ARTIFACTS_DRY_RUN=true).\\n2) Ensure target flow_runs/{runId} has READY LLM_REPORT step with valid inputs and outputs.gcs_uri for ohlcv/charts steps.\\n3) Determine deterministic artifact URI via ArtifactPathPolicy for (runId, timeframe, stepId).\\n4) Ensure object does NOT exist at that URI before positive run (or use a new runId to guarantee).\\n\\nScenario steps (positive):\\n1) Patch flow_runs/{runId}.updatedAt to trigger Firestore update.\\n2) Observe logs for handler flow (ready_step_selected ‚Üí prompt/schema fetch ‚Üí gcs_write_started/gcs_write_finished).\\n3) Verify GCS object exists at deterministic URI.\\n4) Verify Firestore step outputs.gcs_uri equals that deterministic URI.\\n\\nScenario steps (negative / split-brain idempotency):\\nA) Re-trigger same runId (patch updatedAt again) after artifact already exists.\\nB) Expect create-only write to detect AlreadyExists and reuse object (no duplicate object).\\nC) If available, simulate split-brain: artifact exists but Firestore outputs.gcs_uri missing ‚Üí retrigger and ensure outputs.gcs_uri is set without new object.\\n\\nExpected results (positive):\\n- Single object created at deterministic GCS URI (<prefix>/<runId>/<timeframe>/<stepId>.json).\\n- Firestore outputs.gcs_uri set to that URI.\\n- Logs show artifact write success (no errors).\\n\\nExpected results (negative / idempotency):\\n- Re-trigger does NOT create a new object; logs show reuse/AlreadyExists path.\\n- Firestore outputs.gcs_uri remains same; no duplicate LLM calls implied by logs.\\n- If split-brain simulated: outputs.gcs_uri is repaired without new object creation.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic6",
        "verify"
      ],
      "depends_on": [
        "T-037",
        "T-039"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: Epic 6 dev verification (dry-run artifact path)."
        }
      ],
      "commit": {
        "hash": "381d062e706a72ce09c8b64a4f200a6fd63856b4",
        "message": "‚úÖ T-039 close dry-run artifact stub"
      }
    },
    {
      "id": "T-039",
      "title": "E06 Add artifact write stub (debug flag)",
      "description": "Add opt-in stub (ARTIFACTS_DRY_RUN=true) to generate a minimal LLMReportFile (metadata + empty output) and write it via ArtifactStore create-only path without calling Gemini. Gate by env flag; default off. Use ArtifactPathPolicy deterministic URI; log gcs_write_started/gcs_write_finished (include ok + reused flag) and patch steps.<stepId>.outputs.gcs_uri via FlowRunRepository.patch (precondition update_time). Intended for Epic 6 demo only.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic6",
        "artifacts",
        "debug"
      ],
      "depends_on": [
        "T-036"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: add ARTIFACTS_DRY_RUN stub to write test report artifact."
        }
      ],
      "commit": {
        "hash": "8226d65c8d3ffd3477f87af30d7aec0a60803ba6",
        "message": "üß™ T-039 dry-run artifact stub"
      }
    },
    {
      "id": "T-040",
      "title": "E07 Spike: Gemini multimodal + JSON schema path",
      "description": "Validate Gemini SDK/endpoint constraints for combined image inputs + response JSON schema (SPK-010) and confirm AI Studio vs Vertex choice (SPK-007).\\n\\nDeliverables:\\n- Prototype request using google-genai with: system instruction + user parts + 1-3 PNGs + response_json_schema.\\n- Capture SDK version, model(s) tested, limits (image size/count), and error modes.\\n- Update @docs/questions/arch_spikes.md with results (mark SPK-010/SPK-007 resolved) and update @docs/spec/system_integration.md if constraints change.\\n- Record whether the demo in T-047 can rely on image+schema in one request; note any fallbacks.\\n- No secrets committed; use placeholders in any recorded commands or notes.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic7",
        "spike"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: run Epic 7 spike to validate Gemini multimodal + JSON schema path (SPK-010/007), then update docs with findings."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: ran spike script with SPIKE_VERBOSE=1 using gemini-2.5-flash-lite; image+response_json_schema path returned valid JSON; model may ignore semantic constraints (details.model mismatch)."
        }
      ],
      "commit": {
        "hash": "9659b2ea9d96b50e0aa4b8adf4bf9bcbe9d97b10",
        "message": "‚ú® T-040 validate multimodal schema spike"
      }
    },
    {
      "id": "T-041",
      "title": "E07 Spike: LLM retry/backoff within time budget",
      "description": "Define retry/backoff policy for Gemini calls and structured-output repair within finalize budget (SPK-014).\\n\\nDeliverables:\\n- Map google-genai exceptions to retryable vs non-retryable per @docs/spec/error_and_retry_model.md.\\n- Decide retry approach (tenacity vs custom minimal loop) compatible with finalize budget (no unbounded retries).\\n- Document attempt caps for primary call and repair call (maxRepairAttempts=1).\\n- Update @docs/spec/error_and_retry_model.md and/or @docs/spec/implementation_contract.md with the chosen policy.\\n- Record decisions in @docs/questions/arch_spikes.md (mark SPK-014 resolved).",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic7",
        "spike"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: spike retry/backoff within time budget; map retryable errors and propose policy."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: documented Gemini SDK error mapping + retry envelope (maxGeminiAttempts=1, maxRepairAttempts=1) and marked SPK-014 resolved."
        }
      ],
      "commit": {
        "hash": "a5ceeb80ea1895d61679f2d2da15b79802ce65e4",
        "message": "‚ú® T-041 define Gemini retry envelope"
      }
    },
    {
      "id": "T-042",
      "title": "E07 Implement LLMProfile + StructuredOutputSpec",
      "description": "Implement LLM request profile/value objects used by Epic 7 services.\\n\\nScope:\\n- Add LLMProfile and StructuredOutputSpec to @worker_llm_client/reporting/domain.py (or new module), including validation helpers.\\n- Enforce MVP constraints: responseMimeType=application/json, candidateCount==1 (when present), schemaId pattern llm_report_output_v{N} (schemaVersion parse).\\n- Preserve modelName/model alias resolution; expose modelName for logging.\\n- Ensure invalid profiles raise/return LLMProfileInvalid (mapped to LLM_PROFILE_INVALID).\\n- Update LLMReportInputs to use/return validated profile (no raw dicts) if needed by downstream Epic 7 services.\\n\\nOutcome: downstream LLM adapter and validator can rely on a validated, structured profile object.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic7"
      ],
      "depends_on": [
        "T-039"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement LLMProfile + StructuredOutputSpec per contracts/specs."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: added LLMProfile + StructuredOutputSpec value objects with MVP validation and exports."
        }
      ],
      "commit": {
        "hash": "a7a1199ba5a1fddea73d099c9d148a3017706553",
        "message": "‚ú® T-042 add LLMProfile types"
      }
    },
    {
      "id": "T-043",
      "title": "E07 Implement UserInputAssembler + context resolution",
      "description": "Implement UserInput assembly and context loading per @docs/spec/prompt_storage_and_context.md.\\n\\nScope:\\n- Add UserInputAssembler in @worker_llm_client/reporting/services.py.\\n- Resolve and load context artifacts via ArtifactStore (OHLCV JSON, charts manifest JSON, previous reports).\\n- Enforce size limits: JSON <= 64KB, chart images <= 256KB; violations -> INVALID_STEP_INPUTS.\\n- Produce UserInput text with scope.symbol + step.timeframe and include JSON blocks + chart list.\\n- Return user content parts suitable for Gemini (text parts + optional image bytes) for use in T-045 and demo T-047.\\n- Do not log raw artifact payloads; only sizes/URIs/hashes.\\n\\nOutcome: deterministic UserInput builder that the Gemini adapter can consume.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic7"
      ],
      "depends_on": [
        "T-036",
        "T-042"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement UserInputAssembler + context resolution pipeline."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: added UserInputAssembler with GCS context resolution + size limits and UserInput assembly."
        }
      ],
      "commit": {
        "hash": "c7c0ae955c6940a4ed29999af1662604b5c5f24a",
        "message": "‚ú® T-043 add UserInputAssembler"
      }
    },
    {
      "id": "T-044",
      "title": "E07 Implement StructuredOutputValidator + StructuredOutputInvalid",
      "description": "Implement structured output extraction + JSON Schema validation.\\n\\nScope:\\n- Add StructuredOutputValidator and StructuredOutputInvalid in @worker_llm_client/reporting/services.py and @worker_llm_client/reporting/domain.py.\\n- Deterministic extraction: candidates[0].content.parts[*].text concatenation; fallback to response.text.\\n- JSON parse + validate against llm_schemas/{schemaId}.jsonSchema (use jsonschema lib).\\n- Emit StructuredOutputInvalid with reason.kind (missing_text/json_parse/schema_validation/finish_reason), sanitized message, textBytes, textSha256, finishReason (if any).\\n- Ensure validation never logs raw payloads; provide safe diagnostics only.\\n- Support error mapping used in T-047 demo (INVALID_STRUCTURED_OUTPUT).\\n\\nOutcome: deterministic validator that returns output JSON or a safe error object for logging/step error.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic7"
      ],
      "depends_on": [
        "T-042"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement StructuredOutputValidator + StructuredOutputInvalid per spec."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: added StructuredOutputValidator + StructuredOutputInvalid with sanitized diagnostics; uses jsonschema with minimal fallback."
        }
      ],
      "commit": {
        "hash": "db6c3af81e09038676da770d09b2d061654ec2b0",
        "message": "‚ú® T-044 add structured output validator"
      }
    },
    {
      "id": "T-045",
      "title": "E07 Implement LLMClient port + GeminiClientAdapter",
      "description": "Add provider-neutral LLM client interface and Gemini AI Studio adapter.\\n\\nScope:\\n- Define LLMClient port in @worker_llm_client/app/services.py (or reporting services).\\n- Implement GeminiClientAdapter in @worker_llm_client/infra/gemini.py using google-genai SDK (AI Studio API key).\\n- Support response JSON schema (structured output) and optional image parts; map finishReason + usage metadata.\\n- Add dependency updates in requirements.txt (google-genai, jsonschema).\\n- Map SDK exceptions to retryable/non-retryable errors per @docs/spec/error_and_retry_model.md (no retries yet).\\n- Enforce allowlist via WorkerConfig.is_model_allowed (LLM_PROFILE_INVALID if disallowed).\\n- Keep secrets out of logs; log only llm.auth.mode + modelName + promptId.\\n\\nOutcome: Gemini adapter can execute real requests with structured output and return a provider response DTO for validation.",
      "status": "DONE",
      "priority": "med",
      "owner": "CODER",
      "tags": [
        "epic7"
      ],
      "depends_on": [
        "T-040",
        "T-042"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement LLMClient port + GeminiClientAdapter; wire google-genai usage."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: added LLMClient port + GeminiClientAdapter, provider response DTO, and SDK dependency."
        }
      ],
      "commit": {
        "hash": "fec76366c600f9188ef70fe05152340c877c61cf",
        "message": "‚ú® T-045 add Gemini LLM adapter"
      }
    },
    {
      "id": "T-046",
      "title": "E07 Tests: profile, user input, structured output",
      "description": "Add unit tests for Epic 7 components.\\n\\nScope:\\n- LLMProfile/StructuredOutputSpec validation (responseMimeType, candidateCount, schemaId pattern).\\n- UserInputAssembler: scope/timeframe injection, JSON context assembly, size limit failures.\\n- StructuredOutputValidator: fixtures in @docs/fixtures/structured_output_invalid/* and happy-path schema validation.\\n- Ensure logs/diagnostics never include raw payloads.\\n\\nOutcome: local test coverage for validator + input assembly invariants.",
      "status": "DONE",
      "priority": "med",
      "owner": "TESTER",
      "tags": [
        "epic7"
      ],
      "depends_on": [
        "T-042",
        "T-043",
        "T-044"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: add unit tests for LLMProfile/UserInputAssembler/StructuredOutputValidator."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: pytest -q (69 passed). Added tests for profile/user input/structured output and fixed precondition fallback."
        }
      ],
      "commit": {
        "hash": "e7b8f254d339e6924373469cb4c93c0f14b7172d",
        "message": "‚ú® T-046 fix precondition fallback"
      }
    },
    {
      "id": "T-047",
      "title": "E07 Epic 7 DoD verification (dev)",
      "description": "Epic 7 cloud DoD verification (dev).\\n\\nDemo prerequisites:\\n- Function deployed with Epic 7 code (LLMClient + validator + UserInputAssembler) and ACTIVE.\\n- GEMINI_API_KEY injected via Secret Manager; model allowlist (if set) permits the target model.\\n- Firestore seed docs exist: llm_prompts/{promptId}, llm_schemas/{schemaId}, flow_runs/{runId} with READY LLM_REPORT step referencing ohlcv/charts outputs.\\n- GCS input artifacts exist (OHLCV JSON + charts manifest JSON; optional chart images if used).\\n- Runtime SA has Firestore + GCS + Secret Manager access.\\n\\nDemo preparation steps:\\n1) Environment setup: confirm function revision, env vars (ARTIFACTS_BUCKET, GEMINI_TIMEOUT_SECONDS, LOG_LEVEL), and secret wiring.\\n2) Artifact preparation: verify input GCS URIs exist and are within size limits.\\n3) Configuration: ensure llmProfile has responseMimeType=application/json, candidateCount=1, structuredOutput.schemaId valid.\\n4) Deployment: update the function if any Epic 7 code or env vars changed.\\n\\nPositive scenario:\\n- Description: valid prompt/schema produces valid structured output and report artifact.\\n- Steps:\\n  a) Patch flow_runs/{runId}.updatedAt to trigger Firestore update.\\n  b) Observe logs: prompt_fetch_* ‚Üí context_resolve_* ‚Üí llm_request_* ‚Üí structured_output_* ‚Üí gcs_write_* ‚Üí step_completed ‚Üí cloud_event_finished status=ok.\\n  c) Verify GCS report object at deterministic URI and Firestore steps.<stepId>.outputs.gcs_uri matches it.\\n- Expected results: LLM call succeeds, structured output validates, report artifact exists, no raw output in logs.\\n\\nNegative scenarios:\\n1) Preflight schema invalid (LLM_PROFILE_INVALID):\\n  - Use a flow_run referencing an invalid schema doc (missing required summary.markdown).\\n  - Expect structured_output_schema_invalid and cloud_event_finished status=failed; no llm_request_started.\\n2) Structured output invalid (INVALID_STRUCTURED_OUTPUT):\\n  - Use a prompt/profile that forces truncated/invalid JSON (e.g., very low maxOutputTokens).\\n  - Expect structured_output_invalid + step FAILED with INVALID_STRUCTURED_OUTPUT; no raw output in logs; artifact absent unless failure artifact policy is explicitly enabled.\\n3) Input artifacts exceed size limits (INVALID_STEP_INPUTS):\\n  - Prepare an OHLCV JSON > 64KB or a chart image > 256KB and reference it in the READY step.\\n  - Expect context_resolve_finished ok=false (or explicit error log), no llm_request_started, and step FAILED with INVALID_STEP_INPUTS.\\n  - Logs must include only URI + byte size/hash diagnostics (no raw payload).",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic7",
        "verify"
      ],
      "depends_on": [
        "T-040",
        "T-041",
        "T-042",
        "T-043",
        "T-044",
        "T-045",
        "T-046"
      ],
      "commit": {
        "hash": "e096c60e861ecda1fa3f6edfac42a4fb4590672b",
        "message": "üßæ T-047 log rerun after redeploy"
      },
      "comments": [
        {
          "author": "INTEGRATOR",
          "body": "Verified: pytest -q (73 passed, 1 warning). Rerun on revision worker-llm-client-00012-taz with FIRESTORE_DATABASE set; positive + 4.1/4.2/4.3 executed and logged in workspace README."
        }
      ]
    },
    {
      "id": "T-048",
      "title": "E07 Spike: Gemini image limits (size/count)",
      "description": "Extend SPK-010 with explicit limits on image size and count for multimodal + response_json_schema.\\n\\nDeliverables:\\n- Spike script to sweep image sizes and image counts against gemini-2.5-flash-lite (AI Studio).\\n- Capture max working size/count, error modes/messages, and approximate token usage.\\n- Update @docs/questions/arch_spikes.md with limits summary and any constraints.\\n- Update @docs/spec/system_integration.md if new constraints affect integration guidance.\\n- Record results in @.codex-swarm/workspace/T-048/README.md.\\n- No secrets committed; use placeholders in any recorded commands or notes.",
      "status": "DONE",
      "priority": "med",
      "owner": "DOCS",
      "tags": [
        "epic7",
        "spike"
      ],
      "depends_on": [
        "T-040"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: extend SPK-010 with image size/count limit sweep for multimodal + JSON schema."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: ran size/count sweep for inline PNGs + response_json_schema; all tested (1/4/8 images at 128/512/1024px) succeeded; no limit hit; semantic constraints still require validation."
        }
      ],
      "commit": {
        "hash": "b4c01a5d2584964b1d339580f48305f9fdaa9e35",
        "message": "‚ú® T-048 extend image limit spike"
      }
    },
    {
      "id": "T-049",
      "title": "E07 Deviation: schema invalid does not finalize step",
      "description": "During T-047 negative scenario 4.1 (invalid schema), handler logs structured_output_schema_invalid and cloud_event_finished status=failed, but Firestore step remains READY and no error is written. Expected: step finalized FAILED with error.code=LLM_PROFILE_INVALID and no LLM/GCS side effects. Fix should patch Firestore to FAILED + error, ensure log/metrics consistency, and add/adjust tests to cover this behavior.",
      "status": "DONE",
      "priority": "high",
      "owner": "INTEGRATOR",
      "tags": [
        "epic7",
        "deviation",
        "verify"
      ],
      "depends_on": [
        "T-047"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Observed in dev at 2025-12-30T17:12:37Z during T-047 4.1 (schemaId=llm_report_output_v99)."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: pytest tests/test_firestore_repository.py -q (12 passed, 1 warning). Schema-invalid now finalizes from READY."
        }
      ],
      "commit": {
        "hash": "0c113fb6cba37ec07fdfc10bb9da6c9f4bd06756",
        "message": "‚ú® T-049 finalize schema invalid from READY"
      }
    },
    {
      "id": "T-050",
      "title": "E07 Implement LLM execution path in handler",
      "description": "Wire the real LLM execution path: claim step, resolve inputs (UserInputAssembler), call Gemini via LLMClient, validate structured output, write report artifact, and finalize step status in Firestore. Ensure error paths finalize with correct error.code (LLM_PROFILE_INVALID, INVALID_STRUCTURED_OUTPUT, INVALID_STEP_INPUTS, GEMINI_REQUEST_FAILED/RATE_LIMITED/LLM_SAFETY_BLOCK) and emit llm_request_* + structured_output_* logs without leaking payloads. Add/adjust tests for handler flow and error mapping.",
      "status": "DONE",
      "priority": "high",
      "owner": "INTEGRATOR",
      "tags": [
        "epic7",
        "llm",
        "handler"
      ],
      "depends_on": [
        "T-046"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Needed to run T-047 positive + 4.2/4.3 with real LLM calls; current handler only does dry-run artifact write."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: pytest -q (69 passed, 1 warning) at time of implementation; T-047 rerun confirms LLM path works end-to-end."
        }
      ],
      "commit": {
        "hash": "8ea9b8406c8beb8aa205a153e2cd202c518f7346",
        "message": "‚ú® T-050 wire LLM execution path"
      }
    },
    {
      "id": "T-051",
      "title": "E07 Deviation: runtime SA lacks GCS read access",
      "description": "During T-047 positive scenario run, Cloud Function failed reading OHLCV JSON from GCS with 403 storage.objects.get. Grant runtime SA storage.objects.get (and create as needed) on artifacts bucket, then re-run scenarios. Ensure error is handled gracefully if read fails.",
      "status": "DONE",
      "priority": "high",
      "owner": "INTEGRATOR",
      "tags": [
        "epic7",
        "deviation",
        "gcs"
      ],
      "depends_on": [
        "T-047"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Observed 2025-12-30T17:48:02Z in logs: Forbidden 403 for gs://tda-artifacts-test/20251224-061000_LINKUSDT_demo8/ohlcv_export:1M/1M.json."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: runtime SA granted roles/storage.objectViewer; context_resolve succeeded in T-047 rerun."
        }
      ],
      "commit": {
        "hash": "65c49714ccd0d3cf4966439333e5d8c96a7240a8",
        "message": "üßæ T-051 record GCS IAM fix"
      }
    },
    {
      "id": "T-052",
      "title": "E07 Deviation: success finalize leaves stale error",
      "description": "After a successful LLM run, step status is SUCCEEDED but previous error fields (error.code/message) remain on the step. Update finalize logic to clear error on success (and remove stale error/finishedAt when resetting READY) so Firestore state is consistent.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic7",
        "deviation"
      ],
      "depends_on": [
        "T-047"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Observed 2025-12-30T17:54:46Z: step SUCCEEDED but error.code=INVALID_STEP_INPUTS persisted from earlier failure."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: pytest tests/test_firestore_repository.py -q (11 passed, 1 warning). Success finalize clears error; claim clears error/finishedAt."
        }
      ],
      "commit": {
        "hash": "a573a7a057be3bb9f5b4f720c86c37b2274b71b0",
        "message": "‚ú® T-052 clear stale error on success"
      }
    },
    {
      "id": "T-053",
      "title": "E07 Deviation: chart manifest uses png_gcs_uri key",
      "description": "UserInputAssembler does not recognize chart manifest image key png_gcs_uri; context resolution failed with 'charts manifest contains no valid image URIs'. Add support for snake_case key or normalize manifest export. Ensure charts manifest parsing accepts png_gcs_uri (and possibly other aliases) and add tests.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic7",
        "deviation"
      ],
      "depends_on": [
        "T-047"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Observed 2025-12-30T17:53:20Z: INVALID_STEP_INPUTS 'charts manifest contains no valid image URIs' using manifest.json with png_gcs_uri."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: pytest tests/test_user_input_assembler.py -q (4 passed). Added png_gcs_uri alias support + test."
        }
      ],
      "commit": {
        "hash": "1449040baec13be6b50eb2845ea2784047b755ec",
        "message": "‚ú® T-053 accept png_gcs_uri in chart manifest"
      }
    },
    {
      "id": "T-054",
      "title": "E08 TimeBudgetPolicy + invocation deadline config",
      "description": "Implement TimeBudgetPolicy and invocation deadline config.\n\nScope:\n- Add INVOCATION_TIMEOUT_SECONDS to WorkerConfig (default 780) and document in @docs/spec/deploy_and_envs.md.\n- Implement TimeBudgetPolicy with remaining_seconds(now), can_start_llm_call(now), can_start_repair_call(now).\n- Ensure policy snapshot fields are available for logging (remainingSeconds, finalizeBudgetSeconds).\n- Unit tests for policy math + config parsing.\n\nContribution to Epic 8 demo:\n- Enables time-budget guard in T-057 and negative scenario in T-058.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic8",
        "time_budget"
      ],
      "depends_on": [
        "T-047"
      ],
      "commit": {
        "hash": "b30cf070f91566d7e2781efba6394ea32db4698e",
        "message": "‚ú® T-054 add time budget policy and config"
      },
      "comments": [
        {
          "author": "INTEGRATOR",
          "body": "Verified: pytest tests/test_config.py tests/test_time_budget_policy.py -q (9 passed). Added TimeBudgetPolicy and INVOCATION_TIMEOUT_SECONDS config."
        }
      ]
    },
    {
      "id": "T-055",
      "title": "E08 CloudEventParser service",
      "description": "Introduce CloudEventParser (infra/cloudevents.py) for Firestore CloudEvent parsing.\n\nScope:\n- Parse/validate subject and runId according to @docs/spec/system_integration.md.\n- Handler uses parser; invalid subject/runId -> cloud_event_ignored (reason=invalid_subject) with no Firestore writes.\n- Unit tests for valid/invalid subjects and logging outcomes.\n\nContribution to Epic 8 demo:\n- Ensures deterministic event ingestion and clear no-op behavior before orchestration.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic8",
        "cloudevents"
      ],
      "depends_on": [
        "T-047"
      ],
      "commit": {
        "hash": "8dac548922c1b7df2b5cb4f4ecd726ec8847e531",
        "message": "‚ú® T-055 add CloudEventParser"
      },
      "comments": [
        {
          "author": "INTEGRATOR",
          "body": "Verified: pytest tests/test_cloudevent_parser.py tests/test_handler_logging.py -q (7 passed, 1 warning). CloudEventParser integrated."
        }
      ]
    },
    {
      "id": "T-056",
      "title": "E08 FlowRunEventHandler class",
      "description": "Refactor orchestration into FlowRunEventHandler class in @worker_llm_client/app/handler.py.\n\nScope:\n- Create FlowRunEventHandler.handle(event) that wraps existing orchestration (claim -> prompt/schema -> context -> LLM -> artifact -> finalize).\n- Keep handle_cloud_event as thin wrapper delegating to the class.\n- Update tests to cover class-based handler without changing log taxonomy.\n\nContribution to Epic 8 demo:\n- Provides the E08 application-service structure required by static_model for orchestration and time-budget gating.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic8",
        "handler"
      ],
      "depends_on": [
        "T-055"
      ],
      "commit": {
        "hash": "547f59bf477ecc6db34f6622ddf55453ee9fb45f",
        "message": "‚ú® T-056 add FlowRunEventHandler class"
      },
      "comments": [
        {
          "author": "INTEGRATOR",
          "body": "Verified: pytest tests/test_handler_logging.py -q (6 passed, 1 warning). FlowRunEventHandler class wraps existing handler."
        }
      ]
    },
    {
      "id": "T-057",
      "title": "E08 Time budget gating in handler",
      "description": "Integrate TimeBudgetPolicy guard into orchestration.\n\nScope:\n- Before any external call (LLM and repair), check remainingSeconds >= finalizeBudgetSeconds.\n- If insufficient, do NOT start LLM/GCS calls; finalize FAILED with a stable error.code.\n- Decide error code: add TIME_BUDGET_EXCEEDED to ErrorCode (preferred) or reuse an existing code; update @docs/spec/error_and_retry_model.md and @docs/spec/implementation_contract.md accordingly.\n- Emit policy snapshot in logs (remainingSeconds, finalizeBudgetSeconds, repairPlanned).\n- Unit tests for guard path (no llm_request_started, status FAILED, correct error.code).\n\nContribution to Epic 8 demo:\n- Enables negative time-budget scenario in T-058.",
      "status": "DONE",
      "priority": "high",
      "owner": "INTEGRATOR",
      "tags": [
        "epic8",
        "time_budget"
      ],
      "depends_on": [
        "T-054",
        "T-056"
      ],
      "commit": {
        "hash": "548c65128c22040c19a72468699cdf687692a15f",
        "message": "‚ú® T-057 add time budget guard"
      },
      "comments": [
        {
          "author": "INTEGRATOR",
          "body": "Verified: pytest tests/test_handler_logging.py -q (7 passed, 1 warning). TIME_BUDGET_EXCEEDED guard added + specs updated."
        }
      ]
    },
    {
      "id": "T-058",
      "title": "E08 Cloud demo: orchestration + time budget",
      "description": "Epic 8 cloud demo verifying orchestration + time budget guard.\n\nDemo prerequisites:\n- Dev GCP access and deployed worker (Cloud Functions gen2).\n- Runtime SA has Secret Manager access for GEMINI_API_KEY and GCS read/write (objectViewer/objectCreator) on artifacts bucket.\n- Firestore DB tda-db-europe-west4 and collections flow_runs/llm_prompts/llm_schemas exist.\n- Seed docs: llm_prompts/{promptId}, llm_schemas/{schemaId} valid; flow_runs/{runId} with READY LLM_REPORT step referencing ohlcv/charts outputs; artifacts exist in GCS and within size limits; charts manifest supports gcs_uri or png_gcs_uri.\n- Model allowlist includes gemini-2.5-flash-lite (or selected model).\n\nDemo preparation steps:\n1) Environment setup: confirm revision includes Epic 8 code; env vars ARTIFACTS_BUCKET, FIRESTORE_DATABASE, GEMINI_TIMEOUT_SECONDS, FINALIZE_BUDGET_SECONDS, INVOCATION_TIMEOUT_SECONDS, LOG_LEVEL; secret env GEMINI_API_KEY.\n2) Artifact preparation: verify OHLCV JSON + charts manifest URIs and sizes (<=64KB JSON, <=256KB image).\n3) Configuration: ensure llmProfile responseMimeType=application/json, candidateCount=1, schemaId valid.\n4) Deployment: deploy with CONFIRM_TRIGGER_UNCHANGED=true; ensure revision ACTIVE.\n\nInclude Epic 7 re-validation (from @.codex-swarm/workspace/T-047/README.md):\n- Positive run (LLM success, artifact written).\n- Negative 4.1 schema invalid (LLM_PROFILE_INVALID, no LLM call).\n- Negative 4.2 structured output invalid (INVALID_STRUCTURED_OUTPUT, MAX_TOKENS).\n- Negative 4.3 oversized input (INVALID_STEP_INPUTS, no LLM call).\n- Reuse commands/queries from T-047: scripts/deploy_dev.sh; gcloud functions describe; Firestore REST PATCH to updatedAt + status; gsutil cp for oversized OHLCV; gcloud logging read filters for event chain.\n\nPositive scenario (Epic 8):\n- Description: normal invocation with sufficient time budget.\n- Steps:\n  a) PATCH flow_runs/{runId}.updatedAt to trigger.\n  b) Observe logs: cloud_event_parsed -> ready_step_selected -> prompt_fetch_* -> context_resolve_* -> llm_request_* -> gcs_write_* -> cloud_event_finished status=ok.\n  c) Verify Firestore: status=SUCCEEDED, outputs.gcs_uri set, error absent.\n- Expected results: LLM call succeeds; artifact written; logs include policy snapshot without raw payloads.\n\nNegative scenario (time budget guard):\n- Description: force remainingSeconds < finalizeBudgetSeconds so LLM is not started.\n- Steps:\n  a) Deploy with INVOCATION_TIMEOUT_SECONDS < FINALIZE_BUDGET_SECONDS (e.g., 60 vs 120).\n  b) Set step READY; PATCH updatedAt to trigger.\n  c) Observe logs: no llm_request_started; cloud_event_finished status=failed with policy snapshot.\n  d) Verify Firestore: status=FAILED, error.code = TIME_BUDGET_EXCEEDED (or code chosen in T-057); no artifact write.\n- Expected results: guard prevents LLM; step finalized cleanly; no external side effects.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "epic8",
        "demo"
      ],
      "depends_on": [
        "T-057"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: beginning Epic 8 cloud demo execution steps."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: Epic 8 demo run in dev (positive + time budget + 4.1/4.2/4.3); see @.codex-swarm/workspace/T-058/README.md."
        }
      ],
      "commit": {
        "hash": "2942b47fd66545b72277423420ea3b010c03b9d3",
        "message": "üß™ T-058 document Epic 8 demo run"
      }
    },
    {
      "id": "T-059",
      "title": "Support external previous report references",
      "description": "Allow LLM_REPORT inputs to reference previous reports by explicit GCS URI (external workflow), while keeping previousReportStepIds for same-workflow refs. If both stepId and gcs_uri are provided for an entry, prefer gcs_uri. Invalid refs (missing stepId/gcs_uri, unknown stepId, non-LLM_REPORT step, or missing outputs.gcs_uri) must fail with INVALID_STEP_INPUTS. Update contracts/docs and add tests covering precedence + invalid cases.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "flow_run",
        "inputs",
        "docs"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement external previous report inputs + docs updates."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: updated inputs for external previous reports; docs + tests updated (see @.codex-swarm/workspace/T-059/README.md)."
        }
      ],
      "commit": {
        "hash": "8ef2644e9d3df22b202c741db988e08afe259463",
        "message": "‚ú® T-059 support external previous reports"
      }
    },
    {
      "id": "T-060",
      "title": "Persist full usageMetadata payload",
      "description": "Update LLM report outputs to store the complete usageMetadata object returned by the model (not just minimum token counts). Preserve all fields as-is (including nulls/details), and update contracts/docs/examples/tests accordingly.",
      "status": "DONE",
      "priority": "med",
      "owner": "INTEGRATOR",
      "tags": [
        "usage_metadata",
        "llm",
        "docs"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement full usageMetadata passthrough."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: full usageMetadata passthrough stored; docs/examples updated; pytest tests/test_handler_logging.py -q."
        }
      ],
      "commit": {
        "hash": "8f53bbe38c0067139e22339be5d5ee97c30cfada",
        "message": "‚ú® T-060 persist full usageMetadata"
      }
    },
    {
      "id": "T-061",
      "title": "Add one-command prod deploy + smoke script",
      "description": "Create a production deploy script (one command) that performs update deploy with minimal prep, then runs a short smoke run (1 positive + 1 negative scenario), cleans up any test artifacts, and outputs a summary report. Follow the gen2 deploy playbook; require explicit smoke approval and use placeholders in docs. Update docs to describe usage.",
      "status": "DONE",
      "priority": "high",
      "owner": "INTEGRATOR",
      "tags": [
        "deploy",
        "prod",
        "smoke",
        "docs"
      ],
      "depends_on": [],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: implement prod deploy + smoke script."
        },
        {
          "author": "INTEGRATOR",
          "body": "Verified: prod deploy+smoke script executed; positive PASS, negative finalized; script fixes logged in @.codex-swarm/workspace/T-061/README.md."
        }
      ],
      "commit": {
        "hash": "bc30db01b63e0d0d64085d69239d108690b78891",
        "message": "üîß T-061 fix smoke script + log run"
      }
    },
    {
      "id": "T-062",
      "title": "Add root README for LLM_REPORT entity hierarchy",
      "description": "Create README.md in the repo root that documents the entity hierarchy used to describe a LLM_REPORT step (Firestore flow_run, referenced prompt/schema docs, and the final GCS report artifact), with brief descriptions and links to schemas + examples.",
      "status": "DONE",
      "priority": "low",
      "owner": "DOCS",
      "tags": [
        "docs",
        "llm_report"
      ],
      "depends_on": [],
      "verify": [
        "python3 -m pytest -q"
      ],
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Start: add root README.md describing the LLM_REPORT entity hierarchy (Firestore flow_run + prompt/schema docs + GCS report artifact), with links to schemas/examples."
        },
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: locally ran python3 -m pytest -q (PASS). Docs-only change adds root README.md describing the LLM_REPORT entity hierarchy with schema/example links."
        }
      ],
      "commit": {
        "hash": "fa6a64d640bca6273b6700e1f76c996870611b37",
        "message": "üìù T-062 document LLM_REPORT entity hierarchy"
      }
    },
    {
      "id": "T-063",
      "title": "Fix agentctl finish verify call",
      "description": "Fix NameError in .codex-swarm/agentctl.py cmd_finish (run_verify_commands undefined) so agentctl can close tasks via 'finish' when verify commands are configured.",
      "status": "DONE",
      "priority": "low",
      "owner": "ORCHESTRATOR",
      "tags": [
        "tooling",
        "agentctl"
      ],
      "depends_on": [],
      "verify": [
        "python3 -m pytest -q"
      ],
      "commit": {
        "hash": "e335e3d643764156bb40ae6596a23d9cadbe9a03",
        "message": "üõ†Ô∏è T-063 fix agentctl finish verify"
      },
      "comments": [
        {
          "author": "ORCHESTRATOR",
          "body": "Verified: locally ran python3 -m pytest -q (PASS). Fix removes NameError in agentctl finish path so tasks can be closed when verify commands are configured."
        }
      ]
    }
  ],
  "meta": {
    "schema_version": 1,
    "managed_by": "agentctl",
    "checksum_algo": "sha256",
    "checksum": "bef74bc0d8e7d14835265fc062f2959a991f594f9d7615ac0ddbc19faaa65e62"
  }
}
