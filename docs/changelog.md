# Changelog for docs

## Format

For every meaningful Git commit that changes this documentation pack, add a new entry here in the same commit:
- What changed (concrete, file-level if useful)
- Why it changed (decision / intent)
- Checklist delta (if any)
- Open questions delta (if any)

## Entries

### Unreleased

- Documented dev deploy lessons learned (build SA selection/format, trigger SA IAM, secret access, Cloud Run name conflicts, Python 3.13 functions-framework pin) (spec/deploy_and_envs.md).
- Normalized build service account formatting in deploy script (accepts email or full resource name) (scripts/deploy_dev.sh).
- Fixed Firestore trigger path default handling in deploy script to avoid invalid braces (scripts/deploy_dev.sh).
- Added an optional build service account override to the deploy helper script and noted it in deploy docs (scripts/deploy_dev.sh, spec/deploy_and_envs.md).
- Added a deploy helper script for dev and documented the pipeline usage (scripts/deploy_dev.sh, spec/deploy_and_envs.md).
- Rewrote `plan_wbs.md` to align with the latest `static_model.md`, explicitly allocate every class to a concrete MVP epic, and attach the required architectural spikes per epic (from `questions/arch_spikes.md`) (`plan_wbs.md`, `static_model.md`, `questions/arch_spikes.md`).
- Expanded each epic’s definition-of-done with concrete local vs cloud demo/test scenarios and introduced an explicit “Cloud environment + deploy pipeline” prerequisite epic for Cloud-based acceptance (`plan_wbs.md`).
- Updated the static model to reflect Secret Manager–injected Gemini API key configuration (single-key `GEMINI_API_KEY` vs rotation-friendly `GEMINI_API_KEYS_JSON` + `GEMINI_API_KEY_ID`) and the rule that only `llm.auth.mode/keyId` are loggable (`static_model.md`, `spec/deploy_and_envs.md`, `spec/observability.md`).
- Updated the static model to explicitly include `ClaimResult`/`FinalizeResult` and the recommended `FlowRunRepository.claim_step/finalize_step` API aligned with the Firestore `update_time` precondition implementation (`static_model.md`, `spec/implementation_contract.md`).
- Documented a concrete recommended Firestore claim/finalize implementation for `READY → RUNNING → SUCCEEDED/FAILED` using optimistic `update_time` preconditions (by analogy with other workers) (`spec/implementation_contract.md`).
- Closed SPK-001 (Gemini API key handling): documented Secret Manager → env var injection, rotation runbook, and multi-key config (`GEMINI_API_KEYS_JSON` + `GEMINI_API_KEY_ID`) with strict “never log/persist secrets” rules (`spec/deploy_and_envs.md`, `spec/observability.md`, `questions/open_questions.md`, `questions/arch_spikes.md`).
- Closed structured output open question #44: added 3 negative structured-output fixtures + expected failure patches (truncated JSON, missing required, wrong type) and fixed expected `error.code` mapping (`questions/open_questions.md`, `fixtures/structured_output_invalid/*`, `test_vectors/outputs/*`).
- Closed structured output open questions #35 and #39: persist only `attempts.total` (no per-attempt histories) and do not require/generate `output.summary.html` on MVP (`questions/open_questions.md`, `spec/implementation_contract.md`).
- Closed structured output open question #32: made `llm_schemas/{schemaId}.jsonSchema` the single source of truth for output validation (no Pydantic-as-authority on MVP), and aligned validation/logging wording accordingly (`questions/open_questions.md`, `contracts/llm_schema.md`, `spec/implementation_contract.md`, `spec/error_and_retry_model.md`, `spec/observability.md`).
- Closed structured output open question #38: `output.details` remains free-form on MVP; stability guaranteed via `output.summary.markdown` and future tightening happens via schema version bump (`questions/open_questions.md`, `contracts/llm_schema.md`).
- Strengthened structured output schema pre-flight validation: require the schema to enforce `summary.markdown` (and top-level `summary/details`) and log `structured_output_schema_invalid` on schema misconfiguration (`spec/error_and_retry_model.md`, `spec/observability.md`, `spec/implementation_contract.md`, `contracts/llm_schema.md`, `questions/open_questions.md`).
- Closed structured output open question #33: defined a concrete repair prompt contract (code-owned prompt, second Gemini call only, eligibility by `reason.kind`, safe diagnostics, and no persistence/logging of raw candidate text) (`questions/open_questions.md`, `spec/implementation_contract.md`, `spec/observability.md`).
- Finalized structured output schema versioning: added `metadata.schemaVersion` to `llm_report_file`, required schema ids to follow `llm_report_output_v{N}`, and documented worker validation/mapping rules for backward-compatible evolution (`questions/open_questions.md`, `contracts/llm_report_file.schema.json`, `contracts/examples/llm_report_file.example.json`, `contracts/llm_schema.*`, `contracts/flow_run.schema.json`, `spec/*`).
- Closed structured output open question #31: specified deterministic JSON payload extraction from Gemini responses (candidate[0] parts concatenation, no regex/whitespace normalization, explicit fallback + `reason.kind=missing_text`) and added `diagnostics.extractionMethod` to logs (`questions/open_questions.md`, `spec/implementation_contract.md`, `spec/observability.md`).
- Simplified schema registry storage: `llm_schemas/{schemaId}` stores `jsonSchema` inline in Firestore (no GCS indirection) (`contracts/llm_schema.*`, `questions/open_questions.md`, `spec/implementation_contract.md`).
- Closed structured output open questions: schema boundary is output-only (`LLMReportFile.output`), and large JSON Schemas live in a dedicated Firestore registry `llm_schemas/{schemaId}` referenced from `llmProfile.structuredOutput.schemaId` (added contracts + updated `flow_run` schema and examples) (`questions/open_questions.md`, `spec/system_integration.md`, `spec/implementation_contract.md`, `spec/architecture_overview.md`, `contracts/llm_schema.*`, `contracts/flow_run.schema.json`, `contracts/examples/*`).
- Closed structured output open questions: enforced `candidateCount=1`, clarified no auto-tuning of `maxOutputTokens` on truncation, confirmed no fallback to markdown-only when structured output is required, and tightened data-safety rules for model output (`questions/open_questions.md`, `spec/implementation_contract.md`, `spec/error_and_retry_model.md`, `spec/observability.md`).
- Closed structured output open questions: finalized `finishReason` → `error.code` mapping, failure-artifact policy (no raw output in GCS), and orchestrator terminal-failure policy for `INVALID_STRUCTURED_OUTPUT` (`questions/open_questions.md`, `spec/implementation_contract.md`, `spec/error_and_retry_model.md`, `spec/observability.md`).
- Decided structured output invalidation behavior and made it observable: at most 1 repair attempt when time budget allows; added explicit structured-output invalidation/repair log events and documented safe diagnostics (hash/size + sanitized validation errors) (`questions/open_questions.md`, `spec/observability.md`, `spec/implementation_contract.md`, `spec/error_and_retry_model.md`).
- Expanded structured output specification backlog: decomposed the remaining `INVALID_STRUCTURED_OUTPUT` policy into a concrete checklist of spec decisions to close (schema source-of-truth/versioning, validation strictness, repair strategy, observability, artifacts, and tests) (`questions/open_questions.md`).
- Closed prompt-related blockers: defined minimal MVP Firestore prompt document contract `llm_prompts/{promptId}` (schema + example), specified context injection policy (JSON as text, images as inline bytes, 64KB per-JSON limit, 256KB per-image limit), and decided `scope` is injected via **UserInput** (`contracts/llm_prompt.*`, `contracts/examples/llm_prompt.example.json`, `spec/prompt_storage_and_context.md`, `spec/system_integration.md`, `spec/implementation_contract.md`, `spec/error_and_retry_model.md`, `questions/open_questions.md`).
- Added MVP implementation guidance to reuse proven code via copy-paste from `worker_chart_export` and `worker_ohlcv_export` (logging, CloudEvent parsing, Firestore precondition claim/finalize), keeping this spec pack as the source of truth (`spec/implementation_contract.md`, `spec/handoff_checklist.md`).
- Closed CloudEvent subject parsing open question: documented observed Eventarc gen2 subject pattern (`documents/flow_runs/<runId>`) and strict runId extraction/validation rules (`spec/system_integration.md`, `spec/implementation_contract.md`, `questions/open_questions.md`).
- Closed logging taxonomy open question: standardized structured log envelope fields and added a concrete event catalog + typical ordering for `worker_llm_client` (`spec/observability.md`, `questions/open_questions.md`).
- Closed additional orchestration/error-handling open questions: dependsOn satisfaction rules, timing field placement, missing-dependency failure policy, deterministic GCS reuse on split-brain finalize, optimistic preconditions (no transactions), no flowRunSteps truncation on MVP, no indexing storage on MVP, orchestrator vs worker responsibility, safety block mapping, AI Studio endpoint for MVP, and reaper/out-of-scope zombie recovery (`spec/*.md`, `contracts/flow_run.md`, `questions/open_questions.md`).
- Closed timeout policy open question: set Gemini request deadline to `600s` (10m), Cloud Function timeout to `780s` (13m), and reserved `120s` finalize budget (`spec/implementation_contract.md`, `spec/deploy_and_envs.md`, `spec/error_and_retry_model.md`, `questions/open_questions.md`).
- Decided Gemini request parameters are provided only via `steps.*.inputs.llm.llmProfile` (no overrides from prompt/model defaults), updated canonical contracts/examples/test vectors accordingly, and closed open question #1 (`contracts/*.json`, `contracts/examples/*.json`, `test_vectors/*`, `spec/*.md`, `questions/open_questions.md`).
- Added first-pass spec pack for `worker_llm_client` (Cloud Functions gen2 Firestore-triggered LLM step executor) and filled core spec sections (`spec/*.md`).
- Promoted `flow_run` schema and example into canonical contracts (`contracts/flow_run.schema.json`, `contracts/examples/flow_run.example.json`) and added a human-readable contract note (`contracts/flow_run.md`).
- Promoted canonical JSON Schema for the LLM report JSON file (`contracts/llm_report_file.schema.json`) with an example.
- Added initial test vectors for a `READY` `LLM_REPORT` step and an error scenario (missing prompt) under `test_vectors/`.
- Updated `questions/open_questions.md` with blockers around Gemini request parameters, persisted metadata, artifact naming, and logging event taxonomy.
- Updated checklist completion for covered items (`checklists/component_docs_checklist.ru.md`).
- Expanded the error/retry model with a stable error-code proposal, partial-failure handling patterns, Firestore contention notes, and reference retry parameters (`spec/error_and_retry_model.md`).
- Updated logging contract to include `service`/`env`, CloudEvent correlation (`eventId`), and a stable snake_case event taxonomy aligned with Cloud Logging expectations (`spec/observability.md`).
- Added `cloud_event_parsed` requirement to include compact `flowRunSteps` summaries (id/stepType/status/dependsOn) without leaking step inputs (`spec/observability.md`).
- Added Cloud Functions gen2 performance/scaling notes (Cloud Run-like concurrency and instance bounds; start with `--concurrency=1`) (`spec/architecture_overview.md`).
- Added Python implementation conventions (PEP 8, typing, docstrings, error handling, logging) and env-var style guidance (`spec/implementation_contract.md`, `spec/deploy_and_envs.md`).
- Documented orchestration assumptions (`advance_flow` sets `PENDING→READY`) and future optional `reports/*` indexing; refined open questions to reflect prototype constraints (metadata-in-logs, no attempt history, signed URLs) (`spec/system_integration.md`, `spec/implementation_contract.md`, `questions/open_questions.md`).
- Recorded decisions: persist extended LLM execution metadata in `flow_run`, deterministic GCS naming without attempts/timestamps, and store only `gcs_uri` (no `signed_url`) (`spec/system_integration.md`, `spec/implementation_contract.md`, `questions/open_questions.md`).
- Set canonical GCS URI format to `gs://...` and updated the LLM report file schema accordingly; refreshed `questions/open_questions.md` with the remaining unresolved decisions needed for implementation. (`contracts/llm_report_file.schema.json`, `questions/open_questions.md`).
- Added “semantic gap” open questions around context injection, orchestrator/worker responsibility boundaries, Gemini safety blocking, prompt scope merging, SDK choice, timeouts, and zombie-step recovery (`questions/open_questions.md`).
- Triaged inbox notes on artifact naming + Gemini structured output: standardized GCS artifact paths under `/<runId>/<timeframe>/<stepId>.json`, introduced storage-safe `stepId` canon, switched `LLM_REPORT` inputs to stepId references (`ohlcvStepId`, `chartsManifestStepId`), expanded LLM report file schema with finish metadata (finishReason/modelVersion/usageMetadata), refreshed examples/test vectors, and deleted processed inbox artifacts (`spec/*.md`, `contracts/*.json`, `contracts/examples/*.json`, `test_vectors/*`, `inbox/*`).
- Adjusted `llm_report_file` shape so model structured output lives under `output` (with `output.summary` + `output.details`) while `metadata` remains worker-provided (`contracts/llm_report_file.schema.json`, `contracts/examples/llm_report_file.example.json`).
